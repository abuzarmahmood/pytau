{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# SingleTastePoisson Model Demo - Enhanced with Model Fitting\n",
                "\n",
                "This notebook demonstrates the usage of the SingleTastePoisson model with dummy data,\n",
                "including model fitting and comparison of fit outputs to original data."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "import sys\n",
                "import os\n",
                "import warnings\n",
                "warnings.filterwarnings('ignore')\n",
                "\n",
                "# Add pytau to path\n",
                "sys.path.append(os.path.join(os.path.dirname(os.getcwd()), '..', '..'))\n",
                "\n",
                "from pytau.changepoint_model import SingleTastePoisson, gen_test_array, advi_fit\n",
                "import arviz as az"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Generate Test Data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Generate dummy data with obvious changepoints for Poisson model\n",
                "np.random.seed(42)\n",
                "n_trials = 10\n",
                "n_neurons = 5\n",
                "n_time = 100\n",
                "n_states = 3\n",
                "\n",
                "# Create data with obvious state transitions in firing rates\n",
                "state_rates = [2.0, 8.0, 5.0]  # Different firing rates for each state\n",
                "transition_points = [33, 66]  # Clear transition points\n",
                "\n",
                "test_data = np.zeros((n_trials, n_neurons, n_time), dtype=int)\n",
                "for trial in range(n_trials):\n",
                "    # Add some trial-to-trial variability in transition points\n",
                "    trial_transitions = [t + np.random.randint(-3, 4) for t in transition_points]\n",
                "    trial_transitions = [max(5, min(n_time-5, t)) for t in trial_transitions]\n",
                "    \n",
                "    for neuron in range(n_neurons):\n",
                "        # Add some neuron-specific variability to rates\n",
                "        neuron_rates = [r * (0.7 + 0.6 * np.random.random()) for r in state_rates]\n",
                "        \n",
                "        # Generate data for each state\n",
                "        test_data[trial, neuron, :trial_transitions[0]] = np.random.poisson(neuron_rates[0], trial_transitions[0])\n",
                "        test_data[trial, neuron, trial_transitions[0]:trial_transitions[1]] = np.random.poisson(neuron_rates[1], trial_transitions[1] - trial_transitions[0])\n",
                "        test_data[trial, neuron, trial_transitions[1]:] = np.random.poisson(neuron_rates[2], n_time - trial_transitions[1])\n",
                "\n",
                "print(f\"Generated test data shape: {test_data.shape}\")\n",
                "print(f\"Data range: [{test_data.min()}, {test_data.max()}]\")\n",
                "print(f\"State rates: {state_rates}\")\n",
                "print(f\"Transition points (approx): {transition_points}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Initialize and Generate Model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Initialize model\n",
                "model = SingleTastePoisson(\n",
                "    data_array=test_data,\n",
                "    n_states=n_states,\n",
                "    fit_type='vi'\n",
                ")\n",
                "\n",
                "# Generate the PyMC model\n",
                "pymc_model = model.generate_model()\n",
                "print(\"Model generated successfully\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Fit Model with ADVI"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Fit the model using ADVI\n",
                "print(\"Fitting model with ADVI...\")\n",
                "n_fit = 2000  # Number of ADVI iterations\n",
                "n_samples = 500  # Number of samples to draw\n",
                "\n",
                "fitted_model, approx, lambda_stack, tau_samples, observed_data = advi_fit(pymc_model, n_fit, n_samples)\n",
                "\n",
                "# Sample from the fitted model\n",
                "trace = approx.sample(draws=n_samples)\n",
                "\n",
                "print(f\"Model fitting completed. Final ELBO: {approx.hist[-1]:.2f}\")\n",
                "print(f\"Trace variables: {list(trace.posterior.data_vars)}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Extract and Analyze Fitted Parameters"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Extract fitted parameters\n",
                "lambda_samples = trace.posterior['lambda'].values  # Emission rates\n",
                "tau_samples = trace.posterior['tau'].values  # Changepoint locations\n",
                "\n",
                "print(f\"Lambda (emission rates) shape: {lambda_samples.shape}\")\n",
                "print(f\"Tau (changepoints) shape: {tau_samples.shape}\")\n",
                "\n",
                "# Calculate summary statistics - handle the actual dimensions\n",
                "# Lambda shape is typically (chains, draws, neurons, states)\n",
                "# Tau shape is typically (chains, draws, trials, changepoints)\n",
                "lambda_mean = lambda_samples.mean(axis=(0, 1))  # Average over chains and draws\n",
                "tau_mean = tau_samples.mean(axis=(0, 1))  # Average over chains and draws\n",
                "\n",
                "print(f\"\\nEstimated emission rates (mean across samples):\")\n",
                "for state in range(n_states):\n",
                "    if state < lambda_mean.shape[-1]:  # Check if state exists\n",
                "        rate = lambda_mean[:, state].mean()  # Average across neurons\n",
                "        print(f\"  State {state+1}: {rate:.2f} (true: {state_rates[state]})\")\n",
                "\n",
                "print(f\"\\nEstimated changepoints (mean across samples):\")\n",
                "n_changepoints = min(len(transition_points), tau_mean.shape[-1])\n",
                "for i in range(n_changepoints):\n",
                "    cp = tau_mean[:, i].mean()  # Average across trials\n",
                "    print(f\"  Changepoint {i+1}: {cp:.1f} (true: ~{transition_points[i]})\")\n",
                "\n",
                "# Print convergence information\n",
                "print(f\"\\nELBO convergence (last 10 values): {[f'{x:.2f}' for x in approx.hist[-10:]]}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Visualize Original Data vs Model Fit"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Create comprehensive visualization\n",
                "fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
                "\n",
                "# 1. Original data time series (first neuron, first few trials)\n",
                "ax = axes[0, 0]\n",
                "for trial in range(min(3, test_data.shape[0])):\n",
                "    ax.plot(test_data[trial, 0, :], 'o-', markersize=2, alpha=0.7, label=f'Trial {trial+1}')\n",
                "ax.axvline(x=transition_points[0], color='red', linestyle='--', alpha=0.7, label='True CP 1')\n",
                "ax.axvline(x=transition_points[1], color='red', linestyle='--', alpha=0.7, label='True CP 2')\n",
                "ax.set_title('Original Data - Neuron 1 (First 3 Trials)')\n",
                "ax.set_xlabel('Time')\n",
                "ax.set_ylabel('Count')\n",
                "ax.legend()\n",
                "ax.grid(True, alpha=0.3)\n",
                "\n",
                "# 2. Estimated changepoints distribution\n",
                "ax = axes[0, 1]\n",
                "if tau_samples.shape[-1] >= 2:  # Check if we have changepoints\n",
                "    for i in range(min(2, tau_samples.shape[-1])):\n",
                "        cp_data = tau_samples[0, :, :, i].flatten()  # Flatten across draws and trials\n",
                "        ax.hist(cp_data, bins=20, alpha=0.6, label=f'CP {i+1}', density=True)\n",
                "        if i < len(transition_points):\n",
                "            ax.axvline(x=transition_points[i], color='red', linestyle='--', alpha=0.8)\n",
                "ax.set_title('Estimated Changepoint Distributions')\n",
                "ax.set_xlabel('Time')\n",
                "ax.set_ylabel('Density')\n",
                "ax.legend()\n",
                "ax.grid(True, alpha=0.3)\n",
                "\n",
                "# 3. Estimated vs True emission rates\n",
                "ax = axes[0, 2]\n",
                "if lambda_mean.shape[-1] >= n_states:\n",
                "    estimated_rates = [lambda_mean[:, state].mean() for state in range(n_states)]\n",
                "    x_pos = np.arange(len(state_rates))\n",
                "    width = 0.35\n",
                "    ax.bar(x_pos - width/2, state_rates, width, label='True Rates', alpha=0.7)\n",
                "    ax.bar(x_pos + width/2, estimated_rates, width, label='Estimated Rates', alpha=0.7)\n",
                "    ax.set_title('True vs Estimated Emission Rates')\n",
                "    ax.set_xlabel('State')\n",
                "    ax.set_ylabel('Rate')\n",
                "    ax.set_xticks(x_pos)\n",
                "    ax.set_xticklabels([f'State {i+1}' for i in range(len(state_rates))])\n",
                "    ax.legend()\n",
                "    ax.grid(True, alpha=0.3)\n",
                "\n",
                "# 4. ELBO convergence\n",
                "ax = axes[1, 0]\n",
                "ax.plot(approx.hist)\n",
                "ax.set_title('ELBO Convergence')\n",
                "ax.set_xlabel('Iteration')\n",
                "ax.set_ylabel('ELBO')\n",
                "ax.grid(True, alpha=0.3)\n",
                "\n",
                "# 5. Average response with fitted changepoints\n",
                "ax = axes[1, 1]\n",
                "avg_response = test_data.mean(axis=(0, 1))  # Average across trials and neurons\n",
                "ax.plot(avg_response, 'b-', linewidth=2, label='Observed Data')\n",
                "ax.axvline(x=transition_points[0], color='red', linestyle='--', alpha=0.7, label='True CPs')\n",
                "ax.axvline(x=transition_points[1], color='red', linestyle='--', alpha=0.7)\n",
                "# Plot estimated changepoints\n",
                "if tau_mean.shape[-1] >= 2:\n",
                "    for i in range(min(2, tau_mean.shape[-1])):\n",
                "        cp = tau_mean[:, i].mean()\n",
                "        ax.axvline(x=cp, color='green', linestyle=':', alpha=0.8, \n",
                "                  label='Est. CPs' if i == 0 else '')\n",
                "ax.set_title('Average Response with Changepoints')\n",
                "ax.set_xlabel('Time')\n",
                "ax.set_ylabel('Average Count')\n",
                "ax.legend()\n",
                "ax.grid(True, alpha=0.3)\n",
                "\n",
                "# 6. Data heatmap\n",
                "ax = axes[1, 2]\n",
                "im = ax.imshow(test_data[:, 0, :], aspect='auto', cmap='viridis', interpolation='nearest')\n",
                "ax.set_title('Neuron 1 - Trial x Time Heatmap')\n",
                "ax.set_xlabel('Time')\n",
                "ax.set_ylabel('Trial')\n",
                "plt.colorbar(im, ax=ax, label='Count')\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Model Diagnostics"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Print detailed model diagnostics\n",
                "print(\"=== MODEL DIAGNOSTICS ===\")\n",
                "print(f\"\\nData shape: {test_data.shape}\")\n",
                "print(f\"Number of states: {n_states}\")\n",
                "print(f\"ADVI iterations: {n_fit}\")\n",
                "print(f\"Final ELBO: {approx.hist[-1]:.2f}\")\n",
                "\n",
                "print(f\"\\n=== PARAMETER ESTIMATES ===\")\n",
                "print(\"Emission Rates (lambda):\")\n",
                "if lambda_mean.shape[-1] >= n_states:\n",
                "    for i in range(n_states):\n",
                "        true_rate = state_rates[i]\n",
                "        est_rate = lambda_mean[:, i].mean()\n",
                "        est_std = lambda_samples[0, :, :, i].std()\n",
                "        print(f\"  State {i+1}: {est_rate:.2f} \u00b1 {est_std:.2f} (true: {true_rate:.2f})\")\n",
                "\n",
                "print(\"\\nChangepoints (tau):\")\n",
                "n_changepoints = min(len(transition_points), tau_mean.shape[-1])\n",
                "for i in range(n_changepoints):\n",
                "    true_cp = transition_points[i]\n",
                "    est_cp = tau_mean[:, i].mean()\n",
                "    est_std = tau_samples[0, :, :, i].std()\n",
                "    print(f\"  CP {i+1}: {est_cp:.1f} \u00b1 {est_std:.1f} (true: ~{true_cp})\")\n",
                "\n",
                "print(f\"\\n=== CONVERGENCE ===\")\n",
                "elbo_diff = np.diff(approx.hist[-100:])  # Last 100 iterations\n",
                "print(f\"Mean ELBO change (last 100 iter): {elbo_diff.mean():.4f}\")\n",
                "print(f\"Std ELBO change (last 100 iter): {elbo_diff.std():.4f}\")\n",
                "\n",
                "if abs(elbo_diff.mean()) < 0.01:\n",
                "    print(\"\u2705 Model appears to have converged\")\n",
                "else:\n",
                "    print(\"\u26a0\ufe0f  Model may not have fully converged - consider more iterations\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Summary\n",
                "\n",
                "This enhanced notebook demonstrated:\n",
                "1. **Data Generation**: Creating synthetic Poisson count data with known changepoints\n",
                "2. **Model Initialization**: Setting up the SingleTastePoisson model\n",
                "3. **Model Fitting**: Using ADVI to fit the model to data\n",
                "4. **Parameter Extraction**: Extracting and analyzing fitted parameters\n",
                "5. **Model Validation**: Comparing fitted parameters to true values\n",
                "6. **Visualization**: Comprehensive plots showing:\n",
                "   - Original data patterns\n",
                "   - Estimated vs true changepoints\n",
                "   - Estimated vs true emission rates\n",
                "   - ELBO convergence\n",
                "7. **Diagnostics**: Model convergence and parameter accuracy assessment\n",
                "\n",
                "The SingleTastePoisson model successfully detected the changepoints and estimated the emission rates, demonstrating its effectiveness for analyzing Poisson count data with temporal structure."
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
