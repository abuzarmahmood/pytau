{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# CategoricalChangepoint2D Model Demo - Enhanced with Model Fitting\n",
                "\n",
                "This notebook demonstrates the usage of the CategoricalChangepoint2D model with dummy data,\n",
                "including model fitting and comparison of fit outputs to original data.\n",
                "\n",
                "This model handles categorical/discrete state data with changepoints in the probability distributions."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import numpy as np\n",
                "# Try to import matplotlib, create dummy if not available\n",
                "try:\n",
                "    import matplotlib.pyplot as plt\n",
                "except ImportError:\n",
                "    print('matplotlib not available - creating dummy plt object')\n",
                "    class DummyPlt:\n",
                "        def __getattr__(self, name):\n",
                "            def dummy_func(*args, **kwargs):\n",
                "                pass\n",
                "            return dummy_func\n",
                "    plt = DummyPlt()\n",
                "import sys\n",
                "import os\n",
                "import warnings\n",
                "warnings.filterwarnings('ignore')\n",
                "\n",
                "# Add pytau to path\n",
                "sys.path.append(os.path.join(os.path.dirname(os.getcwd()), '..', '..'))\n",
                "\n",
                "from pytau.changepoint_model import CategoricalChangepoint2D, gen_test_array, advi_fit\n",
                "import arviz as az"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Generate Test Data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Generate dummy categorical data with obvious changepoints\n",
                "np.random.seed(42)\n",
                "n_trials = 10\n",
                "n_time = 100\n",
                "n_states = 3\n",
                "n_categories = 4  # Number of discrete categories/states in the data\n",
                "\n",
                "# Define different probability distributions for each temporal state\n",
                "# Each row represents the probability distribution over categories for that temporal state\n",
                "state_probs = [\n",
                "    [0.6, 0.2, 0.1, 0.1],  # State 1: heavily favors category 0\n",
                "    [0.1, 0.1, 0.6, 0.2],  # State 2: heavily favors category 2\n",
                "    [0.2, 0.5, 0.2, 0.1],  # State 3: favors category 1\n",
                "]\n",
                "transition_points = [33, 66]  # Clear transition points\n",
                "\n",
                "test_data = np.zeros((n_trials, n_time), dtype=int)\n",
                "for trial in range(n_trials):\n",
                "    # Add some trial-to-trial variability in transition points\n",
                "    trial_transitions = [t + np.random.randint(-3, 4) for t in transition_points]\n",
                "    trial_transitions = [max(5, min(n_time-5, t)) for t in trial_transitions]\n",
                "    \n",
                "    # Generate categorical data for each temporal state\n",
                "    # State 1\n",
                "    test_data[trial, :trial_transitions[0]] = np.random.choice(\n",
                "        n_categories, size=trial_transitions[0], p=state_probs[0])\n",
                "    \n",
                "    # State 2\n",
                "    test_data[trial, trial_transitions[0]:trial_transitions[1]] = np.random.choice(\n",
                "        n_categories, size=trial_transitions[1] - trial_transitions[0], p=state_probs[1])\n",
                "    \n",
                "    # State 3\n",
                "    test_data[trial, trial_transitions[1]:] = np.random.choice(\n",
                "        n_categories, size=n_time - trial_transitions[1], p=state_probs[2])\n",
                "\n",
                "print(f\"Generated test data shape: {test_data.shape}\")\n",
                "print(f\"Data range: [{test_data.min()}, {test_data.max()}]\")\n",
                "print(f\"Number of categories: {n_categories}\")\n",
                "print(f\"Number of temporal states: {n_states}\")\n",
                "print(f\"Transition points (approx): {transition_points}\")\n",
                "print(f\"\\nState probability distributions:\")\n",
                "for i, probs in enumerate(state_probs):\n",
                "    print(f\"  State {i+1}: {probs}\")\n",
                "\n",
                "# Show category distribution across the entire dataset\n",
                "print(f\"\\nOverall category distribution:\")\n",
                "for cat in range(n_categories):\n",
                "    count = (test_data == cat).sum()\n",
                "    proportion = count / test_data.size\n",
                "    print(f\"  Category {cat}: {count} ({proportion:.3f})\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Initialize and Generate Model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Initialize model\n",
                "model = CategoricalChangepoint2D(\n",
                "    data_array=test_data,\n",
                "    n_states=n_states,\n",
                "    fit_type='vi'\n",
                ")\n",
                "\n",
                "# Generate the PyMC model\n",
                "pymc_model = model.generate_model()\n",
                "print(\"Model generated successfully\")\n",
                "print(f\"Model handles {n_categories} categories with {n_states} temporal states\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Fit Model with ADVI"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Fit the model using ADVI\n",
                "print(\"Fitting model with ADVI...\")\n",
                "n_fit = 2000  # Number of ADVI iterations\n",
                "n_samples = 500  # Number of samples to draw\n",
                "\n",
                "fitted_model, approx = advi_fit(pymc_model, n_fit, n_samples)\n",
                "\n",
                "# Sample from the fitted model\n",
                "trace = approx.sample(draws=n_samples)\n",
                "\n",
                "print(f\"Model fitting completed. Final ELBO: {approx.hist[-1]:.2f}\")\n",
                "print(f\"Trace variables: {list(trace.posterior.data_vars)}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Extract and Analyze Fitted Parameters"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Extract fitted parameters\n",
                "available_vars = list(trace.posterior.data_vars)\n",
                "print(f\"Available variables: {available_vars}\")\n",
                "\n",
                "# Extract parameters that exist\n",
                "found_params = {}\n",
                "param_names = ['p', 'tau', 'pi', 'alpha', 'beta', 'theta']\n",
                "\n",
                "for param in param_names:\n",
                "    if param in available_vars:\n",
                "        found_params[param] = trace.posterior[param].values\n",
                "        print(f\"{param} shape: {found_params[param].shape}\")\n",
                "\n",
                "# Analyze categorical probabilities\n",
                "if 'p' in found_params:\n",
                "    p_samples = found_params['p']\n",
                "    p_mean = p_samples.mean(axis=(0, 1))  # Average over chains and draws\n",
                "    \n",
                "    print(f\"\\n=== CATEGORICAL PROBABILITY ANALYSIS ===\")\n",
                "    print(f\"Estimated probability distributions by temporal state:\")\n",
                "    \n",
                "    for state in range(min(n_states, p_mean.shape[0] if p_mean.ndim > 1 else 1)):\n",
                "        if p_mean.ndim >= 2:  # states x categories\n",
                "            est_probs = p_mean[state, :]\n",
                "        else:\n",
                "            est_probs = p_mean\n",
                "        \n",
                "        true_probs = state_probs[state] if state < len(state_probs) else \"N/A\"\n",
                "        print(f\"\\n  State {state+1}:\")\n",
                "        print(f\"    Estimated: {[f'{p:.3f}' for p in est_probs]}\")\n",
                "        print(f\"    True:      {true_probs}\")\n",
                "        \n",
                "        # Calculate KL divergence if both are available\n",
                "        if isinstance(true_probs, list) and len(est_probs) == len(true_probs):\n",
                "            # Add small epsilon to avoid log(0)\n",
                "            eps = 1e-8\n",
                "            est_probs_safe = np.array(est_probs) + eps\n",
                "            true_probs_safe = np.array(true_probs) + eps\n",
                "            kl_div = np.sum(true_probs_safe * np.log(true_probs_safe / est_probs_safe))\n",
                "            print(f\"    KL divergence: {kl_div:.4f}\")\n",
                "\n",
                "# Analyze changepoints\n",
                "if 'tau' in found_params:\n",
                "    tau_samples = found_params['tau']\n",
                "    tau_mean = tau_samples.mean(axis=(0, 1))\n",
                "    \n",
                "    print(f\"\\n=== CHANGEPOINT ANALYSIS ===\")\n",
                "    print(f\"Estimated changepoints (mean across samples):\")\n",
                "    n_changepoints = min(len(transition_points), tau_mean.shape[-1] if tau_mean.ndim > 0 else 1)\n",
                "    for i in range(n_changepoints):\n",
                "        cp = tau_mean[..., i].mean() if tau_mean.ndim > 1 else (tau_mean[i] if tau_mean.ndim == 1 else tau_mean)\n",
                "        print(f\"  Changepoint {i+1}: {cp:.1f} (true: ~{transition_points[i]})\")\n",
                "\n",
                "# Print convergence information\n",
                "print(f\"\\nELBO convergence (last 10 values): {[f'{x:.2f}' for x in approx.hist[-10:]]}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Visualize Original Data vs Model Fit"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Create comprehensive visualization\n",
                "fig, axes = plt.subplots(3, 2, figsize=(15, 15))\n",
                "\n",
                "# 1. Original data time series (first few trials)\n",
                "ax = axes[0, 0]\n",
                "colors = ['red', 'blue', 'green', 'orange', 'purple'][:n_categories]\n",
                "for trial in range(min(3, test_data.shape[0])):\n",
                "    y_offset = trial * 0.1  # Slight vertical offset for visibility\n",
                "    for t in range(n_time):\n",
                "        category = test_data[trial, t]\n",
                "        ax.scatter(t, category + y_offset, c=colors[category], s=10, alpha=0.7)\n",
                "\n",
                "ax.axvline(x=transition_points[0], color='black', linestyle='--', alpha=0.7, label='True CP 1')\n",
                "ax.axvline(x=transition_points[1], color='black', linestyle='--', alpha=0.7, label='True CP 2')\n",
                "ax.set_title('Original Categorical Data (First 3 Trials)')\n",
                "ax.set_xlabel('Time')\n",
                "ax.set_ylabel('Category')\n",
                "ax.set_yticks(range(n_categories))\n",
                "ax.legend()\n",
                "ax.grid(True, alpha=0.3)\n",
                "\n",
                "# 2. Category proportions over time\n",
                "ax = axes[0, 1]\n",
                "window_size = 10\n",
                "time_windows = np.arange(window_size//2, n_time - window_size//2)\n",
                "category_props = np.zeros((len(time_windows), n_categories))\n",
                "\n",
                "for i, t in enumerate(time_windows):\n",
                "    window_data = test_data[:, t-window_size//2:t+window_size//2+1]\n",
                "    for cat in range(n_categories):\n",
                "        category_props[i, cat] = (window_data == cat).mean()\n",
                "\n",
                "for cat in range(n_categories):\n",
                "    ax.plot(time_windows, category_props[:, cat], label=f'Category {cat}', \n",
                "           color=colors[cat], linewidth=2)\n",
                "\n",
                "ax.axvline(x=transition_points[0], color='black', linestyle='--', alpha=0.7)\n",
                "ax.axvline(x=transition_points[1], color='black', linestyle='--', alpha=0.7)\n",
                "ax.set_title(f'Category Proportions (Window Size: {window_size})')\n",
                "ax.set_xlabel('Time')\n",
                "ax.set_ylabel('Proportion')\n",
                "ax.legend()\n",
                "ax.grid(True, alpha=0.3)\n",
                "\n",
                "# 3. Estimated vs True probability distributions\n",
                "ax = axes[1, 0]\n",
                "if 'p' in found_params:\n",
                "    p_mean = found_params['p'].mean(axis=(0, 1))\n",
                "    \n",
                "    x_pos = np.arange(n_categories)\n",
                "    width = 0.25\n",
                "    \n",
                "    for state in range(min(n_states, p_mean.shape[0] if p_mean.ndim > 1 else 1)):\n",
                "        if p_mean.ndim >= 2:\n",
                "            est_probs = p_mean[state, :]\n",
                "        else:\n",
                "            est_probs = p_mean\n",
                "        \n",
                "        true_probs = state_probs[state] if state < len(state_probs) else [0] * n_categories\n",
                "        \n",
                "        ax.bar(x_pos + state*width, true_probs, width, \n",
                "              label=f'True State {state+1}', alpha=0.7)\n",
                "        ax.bar(x_pos + state*width, est_probs, width, \n",
                "              label=f'Est State {state+1}', alpha=0.5, hatch='//')\n",
                "\n",
                "    ax.set_title('True vs Estimated Probability Distributions')\n",
                "    ax.set_xlabel('Category')\n",
                "    ax.set_ylabel('Probability')\n",
                "    ax.set_xticks(x_pos + width)\n",
                "    ax.set_xticklabels([f'Cat {i}' for i in range(n_categories)])\n",
                "    ax.legend()\n",
                "    ax.grid(True, alpha=0.3)\n",
                "\n",
                "# 4. ELBO convergence\n",
                "ax = axes[1, 1]\n",
                "ax.plot(approx.hist)\n",
                "ax.set_title('ELBO Convergence')\n",
                "ax.set_xlabel('Iteration')\n",
                "ax.set_ylabel('ELBO')\n",
                "ax.grid(True, alpha=0.3)\n",
                "\n",
                "# 5. Data heatmap\n",
                "ax = axes[2, 0]\n",
                "im = ax.imshow(test_data, aspect='auto', cmap='tab10', interpolation='nearest', vmin=0, vmax=n_categories-1)\n",
                "ax.set_title('Trial x Time Heatmap (Categories)')\n",
                "ax.set_xlabel('Time')\n",
                "ax.set_ylabel('Trial')\n",
                "cbar = plt.colorbar(im, ax=ax, label='Category')\n",
                "cbar.set_ticks(range(n_categories))\n",
                "\n",
                "# 6. Changepoint distributions\n",
                "ax = axes[2, 1]\n",
                "if 'tau' in found_params:\n",
                "    tau_samples = found_params['tau']\n",
                "    if tau_samples.shape[-1] >= 2:\n",
                "        for i in range(min(2, tau_samples.shape[-1])):\n",
                "            cp_data = tau_samples[..., i].flatten()\n",
                "            ax.hist(cp_data, bins=20, alpha=0.6, label=f'CP {i+1}', density=True)\n",
                "            if i < len(transition_points):\n",
                "                ax.axvline(x=transition_points[i], color='red', linestyle='--', alpha=0.8)\n",
                "        ax.set_title('Estimated Changepoint Distributions')\n",
                "        ax.set_xlabel('Time')\n",
                "        ax.set_ylabel('Density')\n",
                "        ax.legend()\n",
                "        ax.grid(True, alpha=0.3)\n",
                "else:\n",
                "    ax.text(0.5, 0.5, 'Changepoint\\nparameters\\nnot available', \n",
                "           ha='center', va='center', transform=ax.transAxes)\n",
                "    ax.set_title('Changepoint Distributions')\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Model Diagnostics"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Print detailed model diagnostics\n",
                "print(\"=== MODEL DIAGNOSTICS ===\")\n",
                "print(f\"\\nData shape: {test_data.shape}\")\n",
                "print(f\"Number of categories: {n_categories}\")\n",
                "print(f\"Number of temporal states: {n_states}\")\n",
                "print(f\"ADVI iterations: {n_fit}\")\n",
                "print(f\"Final ELBO: {approx.hist[-1]:.2f}\")\n",
                "\n",
                "print(f\"\\n=== PARAMETER ESTIMATES ===\")\n",
                "for param_name, param_values in found_params.items():\n",
                "    param_mean = param_values.mean(axis=(0, 1))\n",
                "    param_std = param_values.std()\n",
                "    print(f\"{param_name}:\")\n",
                "    print(f\"  Shape: {param_mean.shape}\")\n",
                "    print(f\"  Overall std: {param_std:.4f}\")\n",
                "\n",
                "# Detailed analysis of categorical probabilities\n",
                "if 'p' in found_params:\n",
                "    p_samples = found_params['p']\n",
                "    p_mean = p_samples.mean(axis=(0, 1))\n",
                "    \n",
                "    print(f\"\\n=== CATEGORICAL PROBABILITY ACCURACY ===\")\n",
                "    total_kl_div = 0\n",
                "    for state in range(min(n_states, p_mean.shape[0] if p_mean.ndim > 1 else 1)):\n",
                "        if p_mean.ndim >= 2:\n",
                "            est_probs = p_mean[state, :]\n",
                "        else:\n",
                "            est_probs = p_mean\n",
                "        \n",
                "        if state < len(state_probs):\n",
                "            true_probs = np.array(state_probs[state])\n",
                "            \n",
                "            # Calculate accuracy metrics\n",
                "            mae = np.mean(np.abs(est_probs - true_probs))\n",
                "            rmse = np.sqrt(np.mean((est_probs - true_probs)**2))\n",
                "            \n",
                "            # KL divergence\n",
                "            eps = 1e-8\n",
                "            est_probs_safe = est_probs + eps\n",
                "            true_probs_safe = true_probs + eps\n",
                "            kl_div = np.sum(true_probs_safe * np.log(true_probs_safe / est_probs_safe))\n",
                "            total_kl_div += kl_div\n",
                "            \n",
                "            print(f\"  State {state+1}:\")\n",
                "            print(f\"    MAE: {mae:.4f}\")\n",
                "            print(f\"    RMSE: {rmse:.4f}\")\n",
                "            print(f\"    KL divergence: {kl_div:.4f}\")\n",
                "    \n",
                "    print(f\"  Average KL divergence: {total_kl_div / n_states:.4f}\")\n",
                "\n",
                "# Changepoint accuracy\n",
                "if 'tau' in found_params:\n",
                "    tau_samples = found_params['tau']\n",
                "    tau_mean = tau_samples.mean(axis=(0, 1))\n",
                "    \n",
                "    print(f\"\\n=== CHANGEPOINT ACCURACY ===\")\n",
                "    n_changepoints = min(len(transition_points), tau_mean.shape[-1] if tau_mean.ndim > 0 else 1)\n",
                "    for i in range(n_changepoints):\n",
                "        true_cp = transition_points[i]\n",
                "        est_cp = tau_mean[..., i].mean() if tau_mean.ndim > 1 else (tau_mean[i] if tau_mean.ndim == 1 else tau_mean)\n",
                "        est_std = tau_samples[..., i].std()\n",
                "        error = abs(est_cp - true_cp)\n",
                "        print(f\"  CP {i+1}: {est_cp:.1f} \u00b1 {est_std:.1f} (true: {true_cp}, error: {error:.1f})\")\n",
                "\n",
                "print(f\"\\n=== CONVERGENCE ===\")\n",
                "elbo_diff = np.diff(approx.hist[-100:])  # Last 100 iterations\n",
                "print(f\"Mean ELBO change (last 100 iter): {elbo_diff.mean():.4f}\")\n",
                "print(f\"Std ELBO change (last 100 iter): {elbo_diff.std():.4f}\")\n",
                "\n",
                "if abs(elbo_diff.mean()) < 0.01:\n",
                "    print(\"\u2705 Model appears to have converged\")\n",
                "else:\n",
                "    print(\"\u26a0\ufe0f  Model may not have fully converged - consider more iterations\")\n",
                "\n",
                "print(f\"\\n=== DATA VALIDATION ===\")\n",
                "# Verify data characteristics match expectations\n",
                "for state, (start, end) in enumerate([(0, transition_points[0]), \n",
                "                                     (transition_points[0], transition_points[1]), \n",
                "                                     (transition_points[1], n_time)]):\n",
                "    state_data = test_data[:, start:end]\n",
                "    print(f\"State {state+1} (time {start}-{end}):\")\n",
                "    \n",
                "    for cat in range(n_categories):\n",
                "        observed_prop = (state_data == cat).mean()\n",
                "        expected_prop = state_probs[state][cat] if state < len(state_probs) else 0\n",
                "        print(f\"  Category {cat}: {observed_prop:.3f} (expected: {expected_prop:.3f})\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Summary\n",
                "\n",
                "This enhanced notebook demonstrated:\n",
                "1. **Data Generation**: Creating synthetic categorical data with known changepoints in probability distributions\n",
                "2. **Model Initialization**: Setting up the CategoricalChangepoint2D model for discrete state data\n",
                "3. **Model Fitting**: Using ADVI to fit the model to categorical time series data\n",
                "4. **Parameter Extraction**: Extracting probability distributions and changepoint locations\n",
                "5. **Model Validation**: Comparing fitted probability distributions to true values using multiple metrics\n",
                "6. **Visualization**: Comprehensive plots showing:\n",
                "   - Original categorical data patterns\n",
                "   - Category proportions over time\n",
                "   - Estimated vs true probability distributions\n",
                "   - ELBO convergence\n",
                "   - Changepoint distributions\n",
                "7. **Diagnostics**: Model convergence, parameter accuracy, and data validation\n",
                "\n",
                "The CategoricalChangepoint2D model successfully detected changepoints in categorical data and estimated the underlying probability distributions for each temporal state. This model is particularly useful for analyzing discrete behavioral states, neural population states, or any categorical time series data where the underlying probabilities change over time."
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
